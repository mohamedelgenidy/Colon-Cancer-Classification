{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io3RaHEzwAO8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3UDnbWMOZ8O"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT2CTNlA1CvX"
      },
      "outputs": [],
      "source": [
        "# Install gdown (if not already installed)\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "# Download the file using its Google Drive file ID\n",
        "!gdown --id 1O4w4RT3sLnufJgO9pgCEbnCtLobiJ8_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etZx_lp1te8E"
      },
      "outputs": [],
      "source": [
        "!unzip /content/Lung_and_Colon_Cancer.zip -d /content/Lung_dataset_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IE10YxqeAuS"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization # Import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGL32RYN2iix"
      },
      "outputs": [],
      "source": [
        "# Define image dimensions and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "num_classes = 2 # Should match the number of subdirectories in Formatted_Colon_Data/Train\n",
        "\n",
        "# Define paths for training and test datasets (using the reorganized paths)\n",
        "# These variables are defined in the cell above (Step 1)\n",
        "train_data_path = doubled_colon_train_path\n",
        "test_data_path = doubled_colon_test_path\n",
        "\n",
        "print(f\"Using Training data path: {train_data_path}\")\n",
        "print(f\"Using Test data path: {test_data_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCy0FtJcAfOm"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Split training data into training and validation\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeOTQG8a2qot"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ1byVFn5klm"
      },
      "outputs": [],
      "source": [
        "# Print the number of samples in each dataset\n",
        "print(f\"Number of training samples: {train_generator.samples}\")\n",
        "print(f\"Number of validation samples: {validation_generator.samples}\")\n",
        "print(f\"Number of test samples: {test_generator.samples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBPFgOZ_VWBp"
      },
      "outputs": [],
      "source": [
        "# Number of images to display\n",
        "num_images = 6\n",
        "\n",
        "# Retrieve a batch of images and labels from the generator\n",
        "augmented_images, labels = next(train_generator)\n",
        "\n",
        "# Duplicate the images and labels to display double the images\n",
        "duplicated_images = np.concatenate([augmented_images, augmented_images], axis=0)\n",
        "duplicated_labels = np.concatenate([labels, labels], axis=0)\n",
        "\n",
        "# Ensure we don't exceed the available images\n",
        "num_images = min(num_images * 2, duplicated_images.shape[0])  # Double the images\n",
        "\n",
        "# Get class indices mapping\n",
        "class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
        "\n",
        "# Create a figure and display the images\n",
        "fig, axes = plt.subplots(2, num_images // 2, figsize=(15, 10))  # Adjust grid for double rows\n",
        "\n",
        "for i in range(num_images):\n",
        "    img = duplicated_images[i]\n",
        "    img = np.clip(img, 0, 1)  # Ensure pixel values are in the [0, 1] range\n",
        "    label_index = np.argmax(duplicated_labels[i])  # Get the class index\n",
        "    label = class_indices[label_index]  # Map index to class name\n",
        "    axes[i // (num_images // 2), i % (num_images // 2)].imshow(img)\n",
        "    axes[i // (num_images // 2), i % (num_images // 2)].axis(\"off\")\n",
        "    axes[i // (num_images // 2), i % (num_images // 2)].set_title(label)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3bcbx1Q3nfd"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Regularization to prevent overfitting\n",
        "    Dense(num_classes, activation='softmax')  # Output layer for classification\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA-_CUsBDOXM"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTM6aCwV3nSE"
      },
      "outputs": [],
      "source": [
        "# Summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoX1TsvU3nEc"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=10,  # Adjust based on your needs\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k08W9ocs3xfF"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/API/Colon_cancer_detector.keras')\n",
        "print(\"Model saved to Colon_cancer_detector.keras\")\n",
        "\n",
        "# Load the model (for inference)\n",
        "loaded_model = load_model('/content/drive/MyDrive/API/Colon_cancer_detector.keras')\n",
        "print(\"Model loaded from Colon_cancer_detector.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re6v91_-5h20"
      },
      "outputs": [],
      "source": [
        "# Evaluate the loaded model\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmEG5c-PSoe-"
      },
      "outputs": [],
      "source": [
        "# Predictions for confusion matrix and classification report\n",
        "y_true = validation_generator.classes\n",
        "y_pred_probs = model.predict(validation_generator, steps=len(validation_generator))\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=validation_generator.class_indices.keys(),\n",
        "            yticklabels=validation_generator.class_indices.keys())\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred, target_names=list(validation_generator.class_indices.keys()))\n",
        "print(\"Classification Report:\\n\", class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXKeA3rRvyM7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/API/Colon_cancer_detector.keras'\n",
        "if not os.path.exists(model_path):\n",
        "    raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "class_names_for_prediction = ['Malignant (Adenocarcinoma)', 'Benign (Benign Tissue)'] # Index 0 is Malignant, Index 1 is Benign\n",
        "\n",
        "\n",
        "def predict_image(img_path):\n",
        "    \"\"\"\n",
        "    Predict the class of the input image and display the results.\n",
        "    \"\"\"\n",
        "    # Check if the image exists\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Image file not found at {img_path}. Please upload the image or check the path.\")\n",
        "        return # Gracefully exit if image not found\n",
        "\n",
        "    # Load the image and resize it to 224x224 pixels\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img) / 255.0  # Normalize pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make a prediction using the loaded model\n",
        "    prediction = loaded_model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "    confidence = np.max(prediction) * 100\n",
        "\n",
        "    # Display prediction results\n",
        "    print(f\"🖼️ Image: {img_path}\")\n",
        "    print(f\"🔍 Prediction: {class_names_for_prediction[predicted_class_index]}\") # Use the ordered list\n",
        "    print(f\"⚡ Confidence: {confidence:.2f}%\")\n",
        "\n",
        "    # Optional: Display the image with predictions\n",
        "    plt.imshow(image.load_img(img_path))\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted: {class_names_for_prediction[predicted_class_index]} ({confidence:.2f}%)\") # Use the ordered list\n",
        "    plt.show()\n",
        "\n",
        "# Example: Predict a colon cancer image\n",
        "img_path_to_predict = \"/content/WhatsApp Image 2025-04-08 at 12.26.53_92940954.jpg\"\n",
        "predict_image(img_path_to_predict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
